{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento\n",
    "## Avaliar o impacto da mudança de iterações no algoritmo de busca PSO\n",
    "\n",
    "\n",
    "### Introdução\n",
    "Após o primeiro passo dado no Experimento 01, é necessário encontrar um valor para o número de iterações do PSO.\n",
    "\n",
    "\n",
    "### Objetivo\n",
    "Este experimento tem como objetivo verificar se existem diferenças entre o número de iterações para o PSO e assim escolher um valor que tenha um ponto de alto custo/benefício entre desempenho (RMSE) e tempo de processamento. \n",
    "Serão usadas as séries de retorno das ações componentes do índice IBOVESPA.\n",
    "\n",
    "Os número de iterações utilizados para comparação serão:\n",
    "* 10.\n",
    "* 30.\n",
    "* 50.\n",
    "* 80.\n",
    "* 100.\n",
    "* 150.\n",
    "* 200.\n",
    "\n",
    "### Metodologia\n",
    "\n",
    "1. Primeiro passo é conseguir a base de dados, foi possível através do sistema do Yahoo! Finance conseguir alguns dos dados do IBOVESPA ( 43 dos 70 componentes ).\n",
    "\n",
    "2. Transformar a série de preços em valores de retorno e criar uma matriz de padrões de entrada e saída, segundo o parâmetro de número de lags, para esse experimento foi escolhido o valor 4.\n",
    "\n",
    "3. Para conseguir alguma relevância estatística serão feitas 50 execuções de um cross-validation para cada valor de iteração, a variável a ser analisada será o valor da raiz quadrada do erro médio quadrático (RMSE) resultante.\n",
    "\n",
    "4. Será gerada uma matriz de 50 linhas e 7 colunas contendo todos os resultados obtidos, a primeira análise feita é se a distribuição dos valores de RMSE de cada iteração é igual, para tal foi usado um teste estatístico não-paramétrico, o **'Kruskal-Wallis H-test'**. Esse teste é o equivalente não-paramétrico do ANOVA e sua hipótese nula afirma que as distribuições dos grupos são iguais, se rejeitada é calculada uma matriz de 7 linhas e 7 colunas para verificar essas diferenças, cada elemento da matriz é o resultado de um teste não-paramétrico entre os pares de iterações 'i' e 'j', o teste é o mesmo realizado anteriormente, porém quando o número de grupos é 2 (teste pareado) ele é conhecido por **'Mann–Whitney U test'**, equivalente não paramétrico do t-test.\n",
    "\n",
    "5. O mesmo procedimento é feito para os tempos de execução.\n",
    "\n",
    "6. Se as matrizes forem criadas, ou seja, existe diferença estatística entre os número de iteração do PSO, é calculado um vetor com a soma de cada linha da matriz para criar um ranking desses valores em relação aos outros. \n",
    "\n",
    "Então cada elemento do vetor varia entre 0 e 6, onde o primeiro representa que aquele algoritmo não foi pior que nenhum outro e 6 indica que ele foi pior que todos os outros.\n",
    "\n",
    "Esse experimento foi feito utilizando 3 diferentes regressores, para verificar se os resultados eram consistentes entre diferentes técnicas de Machine Learning, foram escolhidos o **elmK**, **elmR** e **svr**.\n",
    "\n",
    "### Descrição"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código - Inicialização\n",
    "\n",
    "Importação da biblioteca **pai** ( Portfolio-AI ) e definição dos algoritmos de busca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tools import *\n",
    "\n",
    "import pai\n",
    "\n",
    "assets = open('ibovespa.txt', 'r').read().split('\\n')\n",
    "results_path = \"results/\"\n",
    "search_function = \"particle swarm\"\n",
    "evals = [10, 30, 50, 80, 100, 150, 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código - Run\n",
    "\n",
    "Para realizar a busca através do método regressor.search_param() foram utilizados alguns parâmetros extras:\n",
    "* Tipo do cross-validation: time series cross-validation\n",
    "* Número de folds do cross-validation: 10\n",
    "* Algoritmo de busca: PSO\n",
    "* Função objetivo a ser otimizada: RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(name):\n",
    "\n",
    "    r = pai.Regressor(name)\n",
    "\n",
    "    if not os.path.exists(results_path):\n",
    "        os.makedirs(results_path)\n",
    "\n",
    "    for i, asset in enumerate(assets):\n",
    "\n",
    "        filename = results_path + name + \"_\" + asset + \".p\"\n",
    "\n",
    "        if check(filename):\n",
    "            try:\n",
    "                stock = get_data(asset)\n",
    "                stock.create_database(4, series_type=\"return\")\n",
    "                data = stock.get_database()\n",
    "\n",
    "                result = {\"finished\": False}\n",
    "\n",
    "                for ev in evals:\n",
    "                    result[ev] = {}\n",
    "\n",
    "                    print(asset, ev)\n",
    "\n",
    "                    metrics = []\n",
    "                    time = []\n",
    "                    for it in range(50):\n",
    "                        start = datetime.datetime.now()\n",
    "                        r.search_param(database=data, cv=\"ts\", cv_nfolds=10,\n",
    "                                       of=\"rmse\", opt_f=search_function, eval=ev,\n",
    "                                       print_log=False, kf=[\"rbf\"], f=[\"sigmoid\"])\n",
    "                        end = datetime.datetime.now()\n",
    "                        delta = end - start\n",
    "\n",
    "                        time.append(delta.total_seconds())\n",
    "                        metrics.append(r.regressor.cv_best_error)\n",
    "\n",
    "                    result[ev][\"cv\"] = metrics\n",
    "                    result[ev][\"cv_mean\"] = np.mean(metrics)\n",
    "                    result[ev][\"cv_std\"] = np.std(metrics)\n",
    "\n",
    "                    result[ev][\"time\"] = time\n",
    "                    result[ev][\"time_mean\"] = np.mean(time)\n",
    "                    result[ev][\"time_std\"] = np.std(time)\n",
    "\n",
    "                cvs = [result[ev][\"cv\"] for ev in evals]\n",
    "                ts = [result[ev][\"time\"] for ev in evals]\n",
    "\n",
    "                # Create paired test matrices only if exists differences among\n",
    "                # sample distributions\n",
    "                if not non_parametric_check_samples(cvs):\n",
    "                    cv_nparam = matrix_non_parametric_paired_test(cvs)\n",
    "                    result[\"cv_nparam\"] = cv_nparam\n",
    "\n",
    "                if not non_parametric_check_samples(ts):\n",
    "                    t_nparam = matrix_non_parametric_paired_test(ts)\n",
    "                    result[\"t_nparam\"] = t_nparam\n",
    "\n",
    "                result[\"finished\"] = True\n",
    "                pickle.dump(result, open(filename, \"wb\"))\n",
    "\n",
    "                import pprint\n",
    "                pprint.pprint(result)\n",
    "\n",
    "            except:\n",
    "                print(\"Error: \", asset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código - Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analysis(name):\n",
    "    time_means_mx = []\n",
    "    cv_means_mx = []\n",
    "    ranks_mx = []\n",
    "\n",
    "    for asset in assets:\n",
    "        filename = results_path + name + \"_\" + asset + \".p\"\n",
    "\n",
    "        try:\n",
    "            result = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "            if result[\"finished\"]:\n",
    "                print(name, \"Asset: \", asset)\n",
    "                # print(result[\"cv_nparam\"])\n",
    "                # print()\n",
    "\n",
    "                if \"cv_nparam\" not in result:\n",
    "                    print()\n",
    "                    for i in evals:\n",
    "                        print(i)\n",
    "                        print(result[i][\"cv\"])\n",
    "\n",
    "                    tests = [result[sf][\"cv\"] for sf in evals]\n",
    "                    print(non_parametric_check_samples(tests))\n",
    "                    test_nparam = matrix_non_parametric_paired_test(tests)\n",
    "                    print(\"cv_nparam\")\n",
    "                    print(test_nparam)\n",
    "\n",
    "\n",
    "                ranks = []\n",
    "                time_means = []\n",
    "                cv_means = []\n",
    "                for i in range(result[\"cv_nparam\"].shape[0]):\n",
    "                    cv_means.append(result[evals[i]][\"cv_mean\"])\n",
    "                    time_means.append(result[evals[i]][\"time_mean\"])\n",
    "                    ranks.append(np.sum(result[\"cv_nparam\"][i, :]))\n",
    "                    # sum = np.sum(result[\"cv_nparam\"][i, :])\n",
    "                    # print(evals[i], \" is worst than \", sum, \" functions\")\n",
    "                # print()\n",
    "\n",
    "                cv_means_mx.append(cv_means)\n",
    "                time_means_mx.append(time_means)\n",
    "                ranks_mx.append(ranks)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            # print(\"Error: \", asset)\n",
    "            # print()\n",
    "\n",
    "    cv = np.array(cv_means_mx)\n",
    "    ts = np.array(time_means_mx)\n",
    "    rk = np.array(ranks_mx)\n",
    "\n",
    "    cv_mean, cv_std = mean_std(cv, \"cv\")\n",
    "    ts_mean, ts_std = mean_std(ts, \"ts\")\n",
    "    rk_mean, rk_std = mean_std(rk, \"rk\")\n",
    "    print()\n",
    "    print(\"Evaluations | Ranking Sums\")\n",
    "    for j, ev in enumerate(evals):print(ev, \": \", np.sum(rk[:, j]))\n",
    "    print()\n",
    "\n",
    "    rk_samples = [rk[:, j] for j in range(rk.shape[1])]\n",
    "    print(\"Rankings have same distribution: \",\n",
    "          non_parametric_check_samples(rk_samples))\n",
    "    rk_final = matrix_non_parametric_paired_test(rk_samples)\n",
    "    # print(\"Rk final:\")\n",
    "    # print(rk_final)\n",
    "    # print()\n",
    "\n",
    "    print(rk.shape)\n",
    "    print(\"(Evaluations | Rank | Rank Mean | Time Mean)\")\n",
    "    rank = [(evals[i], np.sum(rk_final[i, :]), rk_mean[i], ts_mean[i]) for i in range(rk_final.shape[0])]\n",
    "    rank = sorted(rank, key=lambda f: f[1] + f[2])\n",
    "    print()\n",
    "    for r in rank:print(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código - Run elmK\n",
    "\n",
    "Rodando a análise dos dados gerados pelo regressor **elmK**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elmk Asset:  ABEV3.SA\n",
      "elmk Asset:  BBAS3.SA\n",
      "elmk Asset:  BBDC3.SA\n",
      "elmk Asset:  BBSE3.SA\n",
      "elmk Asset:  BISA3.SA\n",
      "elmk Asset:  BRKM5.SA\n",
      "elmk Asset:  BRML3.SA\n",
      "elmk Asset:  BRPR3.SA\n",
      "elmk Asset:  BVMF3.SA\n",
      "elmk Asset:  CCRO3.SA\n",
      "elmk Asset:  CESP6.SA\n",
      "elmk Asset:  CIEL3.SA\n",
      "elmk Asset:  CMIG4.SA\n",
      "elmk Asset:  CPFE3.SA\n",
      "elmk Asset:  CPLE6.SA\n",
      "elmk Asset:  CRUZ3.SA\n",
      "elmk Asset:  CSAN3.SA\n",
      "elmk Asset:  CYRE3.SA\n",
      "elmk Asset:  DTEX3.SA\n",
      "elmk Asset:  ECOR3.SA\n",
      "elmk Asset:  ELET3.SA\n",
      "elmk Asset:  ELET6.SA\n",
      "elmk Asset:  ELPL4.SA\n",
      "elmk Asset:  EVEN3.SA\n",
      "elmk Asset:  ITUB4.SA\n",
      "elmk Asset:  LIGT3.SA\n",
      "elmk Asset:  MMXM3.SA\n",
      "elmk Asset:  MRFG3.SA\n",
      "elmk Asset:  MRVE3.SA\n",
      "elmk Asset:  NATU3.SA\n",
      "elmk Asset:  OIBR4.SA\n",
      "elmk Asset:  PDGR3.SA\n",
      "elmk Asset:  PETR3.SA\n",
      "elmk Asset:  PETR4.SA\n",
      "elmk Asset:  QUAL3.SA\n",
      "elmk Asset:  RSID3.SA\n",
      "elmk Asset:  SBSP3.SA\n",
      "elmk Asset:  SUZB5.SA\n",
      "elmk Asset:  TBLE3.SA\n",
      "elmk Asset:  TIMP3.SA\n",
      "elmk Asset:  VALE3.SA\n",
      "elmk Asset:  VALE5.SA\n",
      "elmk Asset:  VIVT4.SA\n",
      "\n",
      "Evaluations | Ranking Sums\n",
      "10 :  246.0\n",
      "30 :  190.0\n",
      "50 :  142.0\n",
      "80 :  67.0\n",
      "100 :  45.0\n",
      "150 :  27.0\n",
      "200 :  0.0\n",
      "\n",
      "Rankings have same distribution:  False\n",
      "(43, 7)\n",
      "(Evaluations | Rank | Rank Mean | Time Mean)\n",
      "\n",
      "(200, 0.0, 0.0, 28.985874090232553)\n",
      "(150, 1.0, 0.62790697674418605, 8.0852170162790706)\n",
      "(100, 2.0, 1.0465116279069768, 5.3256890544186044)\n",
      "(80, 3.0, 1.558139534883721, 4.2537387520930245)\n",
      "(50, 4.0, 3.3023255813953489, 2.5558480488372095)\n",
      "(30, 5.0, 4.4186046511627906, 1.5598874967441858)\n",
      "(10, 6.0, 5.7209302325581399, 0.56767122976744189)\n"
     ]
    }
   ],
   "source": [
    "analysis(\"elmk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado - elmK\n",
    "\n",
    "####1.\n",
    "\n",
    "Evaluations | Ranking Sums |\n",
    "-----------------|--------------|\n",
    "10 |  246.0\n",
    "30 |  190.0\n",
    "50 |  142.0\n",
    "80 |  67.0\n",
    "100 |  45.0\n",
    "150 |  27.0\n",
    "200 |  0.0\n",
    "\n",
    "O resultado do elmK mostra o que era esperado, quanto maior o número de iterações, melhor o resultado alcançado.\n",
    "\n",
    "Além disso é feita mais uma checagem para dar uma força estatística ao resultado, é criada uma matriz contendo o vetor de rankings de cada uma das séries verificadas, formando assim uma matriz de 43 linhas e 7 colunas.\n",
    "\n",
    "####2.\n",
    "\n",
    "É feito um teste não-paramétrico para verificar se os rankings apresentam uma mesma distribuição.\n",
    "\n",
    ">Rankings have same distribution:  **False**\n",
    "\n",
    "A hipótese nula foi negada, então é criada uma matriz quadrada contendo os resultados dos testes não-paramétricos pareados. A partir dela, gera-se um vetor final contendo o  ranking.\n",
    "\n",
    "####3.\n",
    "\n",
    "Com isso temos o resultado final:\n",
    "\n",
    "Evaluations | Rank | Rank Mean | Time Mean\n",
    "------------------|----|----------|------------\n",
    "200 | 0.0 | 0.0 | 28.985874090232553\n",
    "150 | 1.0 | 0.62790697674418605| 8.0852170162790706\n",
    "100 | 2.0 | 1.0465116279069768| 5.3256890544186044\n",
    "80| 3.0 | 1.558139534883721| 4.2537387520930245\n",
    "50|  4.0| 3.3023255813953489| 2.5558480488372095\n",
    "30|  5.0| 4.4186046511627906| 1.5598874967441858\n",
    "10|  6.0| 5.7209302325581399| 0.56767122976744189\n",
    "\n",
    "\n",
    "Pelo resultado final fica evidente que quanto maior o número de iterações, melhor!\n",
    "\n",
    "### Resultado - elmR\n",
    "\n",
    "####4.\n",
    "\n",
    "Realizando a análise nos dados gerados pelo elmR:\n",
    "\n",
    "Evaluations | Ranking Sums |\n",
    "-----------------|--------------|\n",
    "10 |  258.0\n",
    "30 |  207.0\n",
    "50 |  155.0\n",
    "80 |  73.0\n",
    "100 |  42.0\n",
    "150 |  20.0\n",
    "200 |  11.0\n",
    "\n",
    ">Rankings have same distribution:  **False**\n",
    "\n",
    "Evaluations | Rank | Rank Mean | Time Mean\n",
    "------------------|----|----------|------------\n",
    "200 | 0.0 | 0.2558139534883721| 22.978089282790702\n",
    "150 | 0.0 | 0.46511627906976744| 17.809725481395347\n",
    "100 | 2.0 | 0.97674418604651159| 11.770818281860464\n",
    "80| 3.0 | 1.6976744186046511| 9.3961927283720943\n",
    "50|  4.0| 3.6046511627906979| 5.8645047386046514\n",
    "30|  5.0| 4.8139534883720927| 3.6145857646511628\n",
    "10|  6.0| 6.0| 1.3012885176744184\n",
    "\n",
    "### Resultado - svr\n",
    "####5.\n",
    "\n",
    "Realizando a análise nos dados gerados pelo svr:\n",
    "\n",
    "Evaluations | Ranking Sums |\n",
    "-----------------|--------------|\n",
    "10 |  166.0\n",
    "30 |  102.0\n",
    "50 |  64.0\n",
    "80 |  48.0\n",
    "100 |  45.0\n",
    "150 |  27.0\n",
    "200 |  0.0\n",
    "\n",
    ">Rankings have same distribution:  **False**\n",
    "\n",
    "Evaluations | Rank | Rank Mean | Time Mean\n",
    "------------------|----|----------|------------\n",
    "200 | 0.0 | 0.0| 15.064930754482758\n",
    "150 | 1.0 | 0.93103448275862066| 11.067770089655168\n",
    "100 | 2.0 | 1.5517241379310345| 7.8917772793103431\n",
    "80| 2.0 | 1.6551724137931034| 5.4089081331034476\n",
    "50|  4.0| 2.2068965517241379| 3.6380196351724141\n",
    "30|  5.0| 3.5172413793103448| 2.9917879227586202\n",
    "10|  6.0| 5.7241379310344831| 2.8240568124137928\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "\n",
    "Os resultados têm uma tendência a melhorarem a medida que o valor comparado cresce, então \n",
    "\n",
    "Para a continuação dos experimentos, usarei o valor 100."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
